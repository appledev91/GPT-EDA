{
    "sqlite_file_path": "pages/src/Database/sqlite",
    "postgres_host": "127.0.0.1",
    "postgres_port": 5432,
    "postgres_dbname": "DATABASE NAME",
    "postgres_user": "POSTGRES USER NAME",
    "postgres_password": "POSTGRES PASSWORD",
    "current_table_name": "gapminder-unclean",
    "csv_file_path": "pages/src/Database/csvdata",
    "xlsx_file_path": "pages/src/Database/xlsxdata",
    "html_charts_sweet": "pages/src/Database/charts",
    "llm_category": [
        "gemini models",
        "ollama models",
        "huggingface models",
        "openai models",
        "groq models",
        "antrophic models"
    ],
    "supported_llms": {
        "gemini_llms": [
            "gemini-pro",
            "gemini-1.5-pro-latest"
        ],
        "vision_models": [
            "gemini-pro-vision",
            "gemini-pro-1.5-latest"
        ],
        "huggingface_llms": [
            "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "meta-llama/Meta-Llama-3-8B-Instruct",
            "mistralai/Mistral-7B-v0.3"
        ],
        "openai_llms": [
            "gpt-4",
            "gpt-3.5-turbo"
        ],
        "groq_llms": [
            "mixtral-8x7b-32768",
            "llama3-70b-8192",
            "gemma-7b-it"
        ],
        "antrophic_llms": [
            "claude-3",
            "claude-2"
        ],
        "opensource_llms": [
            "llama3",
            "phi3",
            "wizardlm2",
            "mistral",
            "gemma",
            "mixtral",
            "llama2",
            "codegemma",
            "command-r",
            "command-r-plus",
            "llava",
            "dbrx",
            "codellama",
            "qwen",
            "dolphin-mixtral",
            "llama2-uncensored",
            "deepseek-coder",
            "mistral-openorca",
            "nomic-embed-text",
            "dolphin-mistral",
            "phi",
            "orca-mini",
            "nous-hermes2",
            "zephyr",
            "llama2-chinese",
            "starcoder2",
            "wizard-vicuna-uncensored",
            "vicuna",
            "tinyllama",
            "dolphin-llama3",
            "openhermes",
            "yi",
            "starcoder",
            "openchat",
            "mxbai-embed-large",
            "tinydolphin",
            "wizardcoder",
            "stable-code",
            "neural-chat",
            "phind-codellama",
            "wizard-math",
            "starling-lm",
            "falcon",
            "dolphincoder",
            "nous-hermes",
            "orca2",
            "stablelm2",
            "sqlcoder",
            "dolphin-phi",
            "solar",
            "yarn-llama2",
            "deepseek-llm",
            "codeqwen",
            "llama3-gradient",
            "all-minilm",
            "bakllava",
            "samantha-mistral",
            "xwinlm",
            "medllama2",
            "wizardlm-uncensored",
            "stable-beluga",
            "nous-hermes2-mixtral",
            "wizardlm",
            "codeup",
            "yarn-mistral",
            "everythinglm",
            "meditron",
            "llama-pro",
            "llama3-chatqa",
            "nexusraven",
            "magicoder",
            "stablelm-zephyr",
            "codebooga",
            "mistrallite",
            "wizard-vicuna",
            "llava-llama3",
            "snowflake-arctic-embed",
            "moondream",
            "goliath",
            "open-orca-platypus2",
            "duckdb-nsql",
            "notux",
            "megadolphin",
            "notus",
            "llava-phi3",
            "alfred",
            "falcon2"
        ]
    },
    "eda_report": "pages/src/Database/userdata",
    "chat_log": "pages/src/Database/userdata",
    "unstructured_data": "pages/src/Database/unstructured/preprocessed",
    "relational_vstore": "pages/src/Database/structured/preprocessed",
    "QnA_img": "pages/src/Database/unstructured/Images",
    "Classification_models": "pages/src/Models",
    "pygwalker_config": "",
    "pygwalker_table": "T124OPPE2_Preprocessing_V2",
    "opensource_llms": [
        "llama3",
        "codestral",
        "phi3",
        "aya",
        "mistral",
        "gemma",
        "mixtral",
        "llama2",
        "codegemma",
        "command-r",
        "command-r-plus",
        "llava",
        "qwen",
        "codellama",
        "dolphin-mixtral",
        "llama2-uncensored",
        "deepseek-coder",
        "nomic-embed-text",
        "mistral-openorca",
        "dolphin-mistral",
        "phi",
        "orca-mini",
        "zephyr",
        "nous-hermes2",
        "starcoder2",
        "llama2-chinese",
        "wizard-vicuna-uncensored",
        "vicuna",
        "dolphin-llama3",
        "wizardlm2",
        "yi",
        "tinyllama",
        "mxbai-embed-large",
        "starcoder",
        "openhermes",
        "openchat",
        "tinydolphin",
        "wizardcoder",
        "stable-code",
        "neural-chat",
        "wizard-math",
        "phind-codellama",
        "starling-lm",
        "dolphincoder",
        "stablelm2",
        "nous-hermes",
        "falcon\n          \nArchive",
        "sqlcoder",
        "orca2",
        "codeqwen",
        "dolphin-phi",
        "solar",
        "yarn-llama2",
        "deepseek-llm",
        "llama3-gradient",
        "all-minilm",
        "xwinlm",
        "samantha-mistral",
        "bakllava",
        "wizardlm",
        "stable-beluga",
        "medllama2",
        "wizardlm-uncensored",
        "nous-hermes2-mixtral",
        "llama3-chatqa",
        "yarn-mistral",
        "codeup",
        "everythinglm",
        "llama-pro",
        "meditron",
        "nexusraven",
        "llava-llama3",
        "stablelm-zephyr",
        "magicoder",
        "codebooga",
        "mistrallite",
        "snowflake-arctic-embed",
        "moondream",
        "wizard-vicuna",
        "duckdb-nsql",
        "goliath",
        "open-orca-platypus2",
        "notux",
        "megadolphin",
        "notus",
        "dbrx",
        "llava-phi3",
        "alfred",
        "falcon2",
        "granite-code"
    ]
}